{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53af2baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import activations, layers, models, optimizers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5531801a",
   "metadata": {},
   "source": [
    "# Creating the model (Q1-Q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c5607da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac99ecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = layers.Conv2D(filters= 32, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3))\n",
    "maxpooling = layers.MaxPooling2D((2, 2))\n",
    "flatten = layers.Flatten()\n",
    "dense = layers.Dense(64, activation=activations.relu)\n",
    "output = layers.Dense(1, activation=tf.keras.activations.sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88833a01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for layer in [conv2d,maxpooling,flatten,dense,output]:\n",
    "    model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a19ebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= optimizers.SGD(learning_rate=0.002, momentum=0.8),\n",
    "               loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf45aa6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 74, 74, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 175232)            0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a4e8a4",
   "metadata": {},
   "source": [
    "# Data generators and training (Q3-Q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7429229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1375081d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    './cats-dogs/train',\n",
    "    batch_size=20,\n",
    "    shuffle=True,class_mode=\"binary\",\n",
    "    target_size=(150,150)\n",
    ")\n",
    "\n",
    "val_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    './cats-dogs/validation',\n",
    "    batch_size=20,\n",
    "    shuffle=True,class_mode=\"binary\",\n",
    "    target_size=(150,150)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "53ed8374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 0.6976 - accuracy: 0.5055 - val_loss: 0.6921 - val_accuracy: 0.5650\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 20s 201ms/step - loss: 0.6916 - accuracy: 0.5430 - val_loss: 0.6889 - val_accuracy: 0.4990\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 22s 215ms/step - loss: 0.6889 - accuracy: 0.5640 - val_loss: 0.6864 - val_accuracy: 0.5500\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 20s 202ms/step - loss: 0.6882 - accuracy: 0.5515 - val_loss: 0.6822 - val_accuracy: 0.5760\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 0.6842 - accuracy: 0.5580 - val_loss: 0.6874 - val_accuracy: 0.5070\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 20s 202ms/step - loss: 0.6780 - accuracy: 0.5620 - val_loss: 0.6672 - val_accuracy: 0.5900\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 19s 188ms/step - loss: 0.6752 - accuracy: 0.5880 - val_loss: 0.6699 - val_accuracy: 0.5900\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 0.6704 - accuracy: 0.5910 - val_loss: 0.6718 - val_accuracy: 0.5880\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 19s 191ms/step - loss: 0.6690 - accuracy: 0.5810 - val_loss: 0.6618 - val_accuracy: 0.5930\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 19s 191ms/step - loss: 0.6633 - accuracy: 0.5970 - val_loss: 0.6494 - val_accuracy: 0.6240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15db98760>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bc253d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7c90afec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5629999935626984"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "median_of_training_accuracy = np.median(history.history[\"accuracy\"])\n",
    "median_of_training_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2d75ebcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard deviation of training loss is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.010592746192689049"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"standard deviation of training loss is:\")\n",
    "np.std(history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a926a2d0",
   "metadata": {},
   "source": [
    "# Data augmentation (Q5-Q6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b03cfd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen_aug = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "train_ds_aug = train_gen_aug.flow_from_directory(\n",
    "    './cats-dogs/train',\n",
    "    batch_size=20,\n",
    "    shuffle=True,\n",
    "    class_mode=\"binary\",\n",
    "    target_size=(150,150))\n",
    "\n",
    "\n",
    "val_gen_aug = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_ds_aug = val_gen_aug.flow_from_directory(\n",
    "    './cats-dogs/validation',\n",
    "    batch_size=20,\n",
    "    shuffle=True,\n",
    "    class_mode=\"binary\",\n",
    "    target_size=(150,150))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "afd6236b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 33s 334ms/step - loss: 0.6811 - accuracy: 0.5660 - val_loss: 0.6684 - val_accuracy: 0.5890\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 32s 321ms/step - loss: 0.6776 - accuracy: 0.5680 - val_loss: 0.6870 - val_accuracy: 0.5560\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 31s 314ms/step - loss: 0.6678 - accuracy: 0.5960 - val_loss: 0.6670 - val_accuracy: 0.5740\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 33s 334ms/step - loss: 0.6657 - accuracy: 0.5865 - val_loss: 0.6603 - val_accuracy: 0.6030\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 37s 365ms/step - loss: 0.6669 - accuracy: 0.5990 - val_loss: 0.6645 - val_accuracy: 0.5840\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 33s 331ms/step - loss: 0.6732 - accuracy: 0.5710 - val_loss: 0.6709 - val_accuracy: 0.5680\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 33s 327ms/step - loss: 0.6628 - accuracy: 0.5915 - val_loss: 0.6589 - val_accuracy: 0.5920\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 34s 336ms/step - loss: 0.6651 - accuracy: 0.5905 - val_loss: 0.6580 - val_accuracy: 0.5990\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 33s 328ms/step - loss: 0.6638 - accuracy: 0.5915 - val_loss: 0.6921 - val_accuracy: 0.5470\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 34s 338ms/step - loss: 0.6635 - accuracy: 0.5925 - val_loss: 0.6734 - val_accuracy: 0.5670\n"
     ]
    }
   ],
   "source": [
    "hist_aug = model.fit(\n",
    "    train_ds_aug,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    validation_data=val_ds_aug,\n",
    "    validation_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f1f9561b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6700516521930695"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(hist_aug.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "13dd9a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5745999932289123"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(hist_aug.history[\"val_accuracy\"][-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a126f866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
